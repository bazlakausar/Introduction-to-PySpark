{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataFrames.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKeQxavNAsqI"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n"
      ],
      "metadata": {
        "id": "5ysB2Hz7AuYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n"
      ],
      "metadata": {
        "id": "QGMQUmNqAuWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n"
      ],
      "metadata": {
        "id": "cdaz0DvZAuTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "WaIxT_x7AuRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "wYFssfE3AuOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "findspark.find()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5nplQTCtAuLU",
        "outputId": "4226106b-99a4-4323-9c12-733f2ae66cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.0.0-bin-hadoop3.2/python/pyspark'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "_KhwJ0u9AuIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Data FRame from an RDD"
      ],
      "metadata": {
        "id": "Ya-Uj0fsExFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"language\", \"users\"]\n",
        "data = [(\"java\", \"20000\"), (\"python\", \"30000\"), (\"scala\", \"40000\")]\n",
        "rdd = spark.sparkContext.parallelize(data)\n",
        "rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSis-UYAAuFa",
        "outputId": "68fdc7ed-963c-4c30-e065-6db6b319e99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('java', '20000'), ('python', '30000'), ('scala', '40000')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PySpark RDD’s toDF() method is used to create a DataFrame from existing RDD. Since RDD doesn’t have columns, the DataFrame is created with default column names “_1” and “_2” as we have two columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "NB7AGz0NE5Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfFromRDD1 = rdd.toDF()\n",
        "dfFromRDD1.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmChdS6gAuCW",
        "outputId": "167ac55d-c1bb-4c1d-ad54-8173a65393ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _1: string (nullable = true)\n",
            " |-- _2: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfFromRDD1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLCMODEEDQYY",
        "outputId": "4ff3986f-5f8d-4e10-9e1b-062ed3440d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|    _1|   _2|\n",
            "+------+-----+\n",
            "|  java|20000|\n",
            "|python|30000|\n",
            "| scala|40000|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Data Frame with schema**\n",
        "\n",
        "If you wanted to specify the column names along with their data types, you should create the StructType schema first and then assign this while creating a DataFrame.\n",
        "\n"
      ],
      "metadata": {
        "id": "dG0iNhrRE71D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "data1 = [(\"Smith\", \"Jone\", \"123\", \"M\", 20000),\n",
        "         (\"Nance\", \"watch\", \"456\", \"F\", 10000),\n",
        "         (\"Rani\", \"Singh\", \"234\", \"F\", 30000),\n",
        "         (\"Raju\", \"Thomas\", \"897\", \"M\", 15000),\n",
        "         (\"Ranjan\", \"Sharma\", \"862\", \"M\", 25000)\n",
        "]\n",
        "\n",
        "schema = StructType([ \\\n",
        "    StructField(\"FirstName\", StringType(), True), \\\n",
        "    StructField(\"LastName\", StringType(), True), \\\n",
        "    StructField(\"Id\", StringType(), True), \\\n",
        "    StructField(\"Gender\", StringType(), True), \\\n",
        "    StructField(\"Salary\", IntegerType(), True) \\\n",
        "])\n",
        "\n",
        "df = spark.createDataFrame(data=data1, schema =schema)\n",
        "df.printSchema()\n",
        "df.show()\n",
        "        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmfwjhelFJWG",
        "outputId": "47cb7928-64b2-40a8-df48-8f95e31bdd46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- FirstName: string (nullable = true)\n",
            " |-- LastName: string (nullable = true)\n",
            " |-- Id: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n",
            "+---------+--------+---+------+------+\n",
            "|FirstName|LastName| Id|Gender|Salary|\n",
            "+---------+--------+---+------+------+\n",
            "|    Smith|    Jone|123|     M| 20000|\n",
            "|    Nance|   watch|456|     F| 10000|\n",
            "|     Rani|   Singh|234|     F| 30000|\n",
            "|     Raju|  Thomas|897|     M| 15000|\n",
            "|   Ranjan|  Sharma|862|     M| 25000|\n",
            "+---------+--------+---+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pandasDF = df.toPandas()\n",
        "print(pandasDF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjLllkd91Lsk",
        "outputId": "0e67a49f-b48e-472b-e90b-239444e1fb91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FirstName LastName   Id Gender  Salary\n",
            "0     Smith     Jone  123      M   20000\n",
            "1     Nance    watch  456      F   10000\n",
            "2      Rani    Singh  234      F   30000\n",
            "3      Raju   Thomas  897      M   15000\n",
            "4    Ranjan   Sharma  862      M   25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Data FRame from Text File"
      ],
      "metadata": {
        "id": "lqBaq8doKz1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.read.text(\"/content/TextFile.txt\")"
      ],
      "metadata": {
        "id": "qaj4PEVtK3jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show(2,truncate=False,vertical=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r93tLa_LO5M",
        "outputId": "9d8e807a-e515-40a5-a90e-57634ca4a444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0---------------------------------\n",
            " value | Project Gutenberg’s              \n",
            "-RECORD 1---------------------------------\n",
            " value | Alice’s Adventures in Wonderland \n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark Row\n",
        "\n",
        "It's basically a record/row in a Data Frame\n",
        "\n",
        "It can be imported using : import pyspark.sql.Row"
      ],
      "metadata": {
        "id": "7b1mdpHPFseN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating** **a** **Row** **object**"
      ],
      "metadata": {
        "id": "kMp2HQ1mG4Xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "row=Row(\"james\", 40)\n",
        "print(row[0],\",\"+str(row[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvATKhLUF-pU",
        "outputId": "0b4708c6-3f3e-416c-b019-3ccd77b0982c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "james ,40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row=Row(name=\"Alice\", age=11)\n",
        "print(row)\n",
        "print(row.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImRtsv3BGQR4",
        "outputId": "f5e0b30b-bd08-437f-c455-91592896bc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(name='Alice', age=11)\n",
            "Alice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creaing a custom class from Row\n",
        "\n",
        "We can create a class and access it just like objects"
      ],
      "metadata": {
        "id": "6aFsP4xlHBI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "Person = Row(\"Name\", \"Age\")\n",
        "p1 = Person(\"Jame\", 40)\n",
        "p2 = Person(\"Alice\", 35)\n",
        "print(p1.Name + \",\"+p2.Name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wrUa3Q2HNVa",
        "outputId": "8ce16c05-842d-449d-e122-8d80e25226e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jame,Alice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Row class on PySpark RDD"
      ],
      "metadata": {
        "id": "0xVuA1UKI1_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, Row\n",
        "spark = SparkSession.builder.appName(\"abc.com\").getOrCreate()\n",
        "\n",
        "data = [Row(name = \"James, Smith\", lang = [\"java\", \"python\", \"c\"], state = \"CA\"),\n",
        "        Row(name = \"Michel, Rose\", lang = [\"python\", \"c++\", \"c\"], state = \"NJ\"),\n",
        "        Row(name = \"Robert, Williams\", lang = [\"scala\", \"java\", \"python\"], state = \"NV\")]\n",
        "rdd = spark.sparkContext.parallelize(data)\n",
        "rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnAFURMJJ_Tj",
        "outputId": "64bdb92d-4721-42f6-ec73-e84d79af1af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(name='James, Smith', lang=['java', 'python', 'c'], state='CA'),\n",
              " Row(name='Michel, Rose', lang=['python', 'c++', 'c'], state='NJ'),\n",
              " Row(name='Robert, Williams', lang=['scala', 'java', 'python'], state='NV')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets collect this data and access it using its properties"
      ],
      "metadata": {
        "id": "ah0QO6JCL2og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "collData=rdd.collect()\n",
        "for row in collData:\n",
        "    print(row.name + \",\" +str(row.lang)+ \",\" +str(row.state))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8si3z5BL79R",
        "outputId": "afa980d6-ad87-464b-aea2-48e590005f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "James, Smith,['java', 'python', 'c'],CA\n",
            "Michel, Rose,['python', 'c++', 'c'],NJ\n",
            "Robert, Williams,['scala', 'java', 'python'],NV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using** **a** **Row** **class** **on** **Data** **Frames**"
      ],
      "metadata": {
        "id": "yiQu0BjjM-Nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8m24RpcNJA1",
        "outputId": "76e8a56c-807c-4c8d-b5f8-12c3ff4e92b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- lang: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- state: string (nullable = true)\n",
            "\n",
            "+----------------+--------------------+-----+\n",
            "|            name|                lang|state|\n",
            "+----------------+--------------------+-----+\n",
            "|    James, Smith|   [java, python, c]|   CA|\n",
            "|    Michel, Rose|    [python, c++, c]|   NJ|\n",
            "|Robert, Williams|[scala, java, pyt...|   NV|\n",
            "+----------------+--------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing column names using `toDF()` function"
      ],
      "metadata": {
        "id": "kBz0Eq6SOKlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"FullName\", \"Language\", \"State\"]\n",
        "df = spark.createDataFrame(data).toDF(*columns)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmiCpt8SOaQ8",
        "outputId": "60e58c32-d7c4-4cb5-b166-6b10c0e35d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- FullName: string (nullable = true)\n",
            " |-- Language: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- State: string (nullable = true)\n",
            "\n",
            "+----------------+--------------------+-----+\n",
            "|        FullName|            Language|State|\n",
            "+----------------+--------------------+-----+\n",
            "|    James, Smith|   [java, python, c]|   CA|\n",
            "|    Michel, Rose|    [python, c++, c]|   NJ|\n",
            "|Robert, Williams|[scala, java, pyt...|   NV|\n",
            "+----------------+--------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark Column Class\n",
        "\n",
        "\n",
        "*   It is used to manipulate column values\n",
        "*   To evaluate boolean expressions to filter rows\n",
        "*   To retrieve a value or a part of a value from a Data Frame\n",
        "*   To work with list, map & struct columns.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jiO8rpe7TH2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a column class object"
      ],
      "metadata": {
        "id": "f_dzPue9TqB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit\n",
        "colObj = (\"abc.com\")\n",
        "\n",
        "data = [(\"James\", 22), (\"Ann\", 24)]\n",
        "df = spark.createDataFrame(data).toDF(\"Name\", \"Age\")\n",
        "df.printSchema()\n",
        "\n",
        "df.select(df.Name).show()\n",
        "df.select(df.Age).show()\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "df.select(col(\"Name\")).show()\n",
        "df.select(col(\"Age\")).show()\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK0g8kNBTuEV",
        "outputId": "a50ab2db-63be-4a63-9e69-ca17aca4ea55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            "\n",
            "+-----+\n",
            "| Name|\n",
            "+-----+\n",
            "|James|\n",
            "|  Ann|\n",
            "+-----+\n",
            "\n",
            "+---+\n",
            "|Age|\n",
            "+---+\n",
            "| 22|\n",
            "| 24|\n",
            "+---+\n",
            "\n",
            "+-----+\n",
            "| Name|\n",
            "+-----+\n",
            "|James|\n",
            "|  Ann|\n",
            "+-----+\n",
            "\n",
            "+---+\n",
            "|Age|\n",
            "+---+\n",
            "| 22|\n",
            "| 24|\n",
            "+---+\n",
            "\n",
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|James| 22|\n",
            "|  Ann| 24|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark Column Operators**\n",
        "\n",
        "Allows us to do Arithematic operations on columns using operators."
      ],
      "metadata": {
        "id": "sH6BMfOXeY2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(100,2,1), (200,3,4), (300,4,4)]\n",
        "df = spark.createDataFrame(data).toDF(\"col1\", \"col2\", \"col3\")\n",
        "\n",
        "df.select(df.col1 + df.col2).show()\n",
        "df.select(df.col1 - df.col2).show()\n",
        "df.select(df.col1 * df.col2).show()\n",
        "df.select(df.col1 / df.col2).show()\n",
        "df.select(df.col1 % df.col2).show()\n",
        "\n",
        "df.select(df.col1 > df.col2).show()\n",
        "df.select(df.col1 < df.col2).show()\n",
        "df.select(df.col1 == df.col2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1zUB8G1eewf",
        "outputId": "bd80527a-2f7d-49a4-fe08-45dd1cb215e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|(col1 + col2)|\n",
            "+-------------+\n",
            "|          102|\n",
            "|          203|\n",
            "|          304|\n",
            "+-------------+\n",
            "\n",
            "+-------------+\n",
            "|(col1 - col2)|\n",
            "+-------------+\n",
            "|           98|\n",
            "|          197|\n",
            "|          296|\n",
            "+-------------+\n",
            "\n",
            "+-------------+\n",
            "|(col1 * col2)|\n",
            "+-------------+\n",
            "|          200|\n",
            "|          600|\n",
            "|         1200|\n",
            "+-------------+\n",
            "\n",
            "+-----------------+\n",
            "|    (col1 / col2)|\n",
            "+-----------------+\n",
            "|             50.0|\n",
            "|66.66666666666667|\n",
            "|             75.0|\n",
            "+-----------------+\n",
            "\n",
            "+-------------+\n",
            "|(col1 % col2)|\n",
            "+-------------+\n",
            "|            0|\n",
            "|            2|\n",
            "|            0|\n",
            "+-------------+\n",
            "\n",
            "+-------------+\n",
            "|(col1 > col2)|\n",
            "+-------------+\n",
            "|         true|\n",
            "|         true|\n",
            "|         true|\n",
            "+-------------+\n",
            "\n",
            "+-------------+\n",
            "|(col1 < col2)|\n",
            "+-------------+\n",
            "|        false|\n",
            "|        false|\n",
            "|        false|\n",
            "+-------------+\n",
            "\n",
            "+-------------+\n",
            "|(col1 = col2)|\n",
            "+-------------+\n",
            "|        false|\n",
            "|        false|\n",
            "|        false|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark WithColumnRenamed() to rename a column**"
      ],
      "metadata": {
        "id": "FmZPquaFhHh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "data = [(\"Smith\", \"Jone\", \"123\", \"M\", 20000),\n",
        "         (\"Nance\", \"watch\", \"456\", \"F\", 10000),\n",
        "         (\"Rani\", \"Singh\", \"234\", \"F\", 30000),\n",
        "         (\"Raju\", \"Thomas\", \"897\", \"M\", 15000),\n",
        "         (\"Ranjan\", \"Sharma\", \"862\", \"M\", 25000)\n",
        "]\n",
        "\n",
        "schema = StructType([ \\\n",
        "    StructField(\"FirstName\", StringType(), True), \\\n",
        "    StructField(\"LastName\", StringType(), True), \\\n",
        "    StructField(\"Id\", StringType(), True), \\\n",
        "    StructField(\"Gender\", StringType(), True), \\\n",
        "    StructField(\"Salary\", IntegerType(), True) \\\n",
        "])\n",
        "\n",
        "df = spark.createDataFrame(data=data, schema =schema)\n",
        "df.printSchema()\n",
        "df.show()\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_idPB4g_lghw",
        "outputId": "0a46986b-f80c-416c-8cc5-e7c3e5e2aab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- FirstName: string (nullable = true)\n",
            " |-- LastName: string (nullable = true)\n",
            " |-- Id: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n",
            "+---------+--------+---+------+------+\n",
            "|FirstName|LastName| Id|Gender|Salary|\n",
            "+---------+--------+---+------+------+\n",
            "|    Smith|    Jone|123|     M| 20000|\n",
            "|    Nance|   watch|456|     F| 10000|\n",
            "|     Rani|   Singh|234|     F| 30000|\n",
            "|     Raju|  Thomas|897|     M| 15000|\n",
            "|   Ranjan|  Sharma|862|     M| 25000|\n",
            "+---------+--------+---+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumnRenamed(\"FirstName\", \"fname\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZCjBszilsBV",
        "outputId": "732dcbd8-3e96-401f-fb7e-1346092b82fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---+------+------+\n",
            "| fname|LastName| Id|Gender|Salary|\n",
            "+------+--------+---+------+------+\n",
            "| Smith|    Jone|123|     M| 20000|\n",
            "| Nance|   watch|456|     F| 10000|\n",
            "|  Rani|   Singh|234|     F| 30000|\n",
            "|  Raju|  Thomas|897|     M| 15000|\n",
            "|Ranjan|  Sharma|862|     M| 25000|\n",
            "+------+--------+---+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.withColumnRenamed(\"LasName\", \"lname\") \\\n",
        "      .withColumnRenamed(\"Gender\", \"Sex\")\n",
        "df1.printSchema()\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsX92KCUmLZr",
        "outputId": "6a26cfc4-b812-4e30-aa8f-6c1bb43a5497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- FirstName: string (nullable = true)\n",
            " |-- LastName: string (nullable = true)\n",
            " |-- Id: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n",
            "+---------+--------+---+---+------+\n",
            "|FirstName|LastName| Id|Sex|Salary|\n",
            "+---------+--------+---+---+------+\n",
            "|    Smith|    Jone|123|  M| 20000|\n",
            "|    Nance|   watch|456|  F| 10000|\n",
            "|     Rani|   Singh|234|  F| 30000|\n",
            "|     Raju|  Thomas|897|  M| 15000|\n",
            "|   Ranjan|  Sharma|862|  M| 25000|\n",
            "+---------+--------+---+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Rename Multiple Columns"
      ],
      "metadata": {
        "id": "c8HbFd9bnNeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1.withColumnRenamed(\"FirstName\", \"fname\") \\\n",
        "      .withColumnRenamed(\"LastName\", \"lname\")\n",
        "\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hofe99IVm0rd",
        "outputId": "f13833ed-dd90-47b8-e157-38e4079c0387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+---+------+\n",
            "| fname| lname| Id|Sex|Salary|\n",
            "+------+------+---+---+------+\n",
            "| Smith|  Jone|123|  M| 20000|\n",
            "| Nance| watch|456|  F| 10000|\n",
            "|  Rani| Singh|234|  F| 30000|\n",
            "|  Raju|Thomas|897|  M| 15000|\n",
            "|Ranjan|Sharma|862|  M| 25000|\n",
            "+------+------+---+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use withColumn()\n",
        "\n",
        "\n",
        "*   To change data type of a column\n",
        "*   To update the value of an existing column\n",
        "*   To create a column from an existing column\n",
        "*   To add a new column\n",
        "*   To rename a column\n",
        "*   To drop a column\n",
        "\n"
      ],
      "metadata": {
        "id": "920qMQmnoH0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing Data Type of a column"
      ],
      "metadata": {
        "id": "iZe6mqCyvYEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.withColumn(\"Salary\", col(\"Salary\").cast(\"Float\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8HtCfRHnvZC",
        "outputId": "81d64dd2-c961-4367-e48a-896927ef3c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+---+-------+\n",
            "| fname| lname| Id|Sex| Salary|\n",
            "+------+------+---+---+-------+\n",
            "| Smith|  Jone|123|  M|20000.0|\n",
            "| Nance| watch|456|  F|10000.0|\n",
            "|  Rani| Singh|234|  F|30000.0|\n",
            "|  Raju|Thomas|897|  M|15000.0|\n",
            "|Ranjan|Sharma|862|  M|25000.0|\n",
            "+------+------+---+---+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updating the value of an existig column"
      ],
      "metadata": {
        "id": "0uP19pbpvfsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.withColumn(\"Salary\", col(\"Salary\")*100).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RdBldVNouiA",
        "outputId": "6a5e89c2-5238-4baf-94cf-8b45aa7f7c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+---+-------+\n",
            "| fname| lname| Id|Sex| Salary|\n",
            "+------+------+---+---+-------+\n",
            "| Smith|  Jone|123|  M|2000000|\n",
            "| Nance| watch|456|  F|1000000|\n",
            "|  Rani| Singh|234|  F|3000000|\n",
            "|  Raju|Thomas|897|  M|1500000|\n",
            "|Ranjan|Sharma|862|  M|2500000|\n",
            "+------+------+---+---+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating column from an existing column"
      ],
      "metadata": {
        "id": "uH6VuKM9vmAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.withColumn(\"UpdatedSalary\", col(\"Salary\")*1).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4RBZKlgph-F",
        "outputId": "118c8eb4-73dc-4459-c012-ead5ca6ba1d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+---+------+-------------+\n",
            "| fname| lname| Id|Sex|Salary|UpdatedSalary|\n",
            "+------+------+---+---+------+-------------+\n",
            "| Smith|  Jone|123|  M| 20000|        20000|\n",
            "| Nance| watch|456|  F| 10000|        10000|\n",
            "|  Rani| Singh|234|  F| 30000|        30000|\n",
            "|  Raju|Thomas|897|  M| 15000|        15000|\n",
            "|Ranjan|Sharma|862|  M| 25000|        25000|\n",
            "+------+------+---+---+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding a new column using withColumn() and lit"
      ],
      "metadata": {
        "id": "Ybd_jQcOvrUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.withColumn(\"Country\", lit(\"USA\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs6E-vHgvv8I",
        "outputId": "3bbe8a63-f74e-48cd-9b50-9f44e6690515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+---+------+-------+\n",
            "| fname| lname| Id|Sex|Salary|Country|\n",
            "+------+------+---+---+------+-------+\n",
            "| Smith|  Jone|123|  M| 20000|    USA|\n",
            "| Nance| watch|456|  F| 10000|    USA|\n",
            "|  Rani| Singh|234|  F| 30000|    USA|\n",
            "|  Raju|Thomas|897|  M| 15000|    USA|\n",
            "|Ranjan|Sharma|862|  M| 25000|    USA|\n",
            "+------+------+---+---+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.withColumnRenamed(\"Sex\", \"Gender\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmazxSySwFSb",
        "outputId": "b0818ea7-dfb6-4e96-8bdf-fc16e671c361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+------+------+\n",
            "| fname| lname| Id|Gender|Salary|\n",
            "+------+------+---+------+------+\n",
            "| Smith|  Jone|123|     M| 20000|\n",
            "| Nance| watch|456|     F| 10000|\n",
            "|  Rani| Singh|234|     F| 30000|\n",
            "|  Raju|Thomas|897|     M| 15000|\n",
            "|Ranjan|Sharma|862|     M| 25000|\n",
            "+------+------+---+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.withColumn(\"UpdatedSalary\", col(\"Salary\") *1).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rzrvzp-_wUrH",
        "outputId": "011685c9-9633-4ce4-e96e-067488806ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+---+------+-------------+\n",
            "| fname| lname| Id|Sex|Salary|UpdatedSalary|\n",
            "+------+------+---+---+------+-------------+\n",
            "| Smith|  Jone|123|  M| 20000|        20000|\n",
            "| Nance| watch|456|  F| 10000|        10000|\n",
            "|  Rani| Singh|234|  F| 30000|        30000|\n",
            "|  Raju|Thomas|897|  M| 15000|        15000|\n",
            "|Ranjan|Sharma|862|  M| 25000|        25000|\n",
            "+------+------+---+---+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.drop(\"UpdatedSalary\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgEv6WiuwlX3",
        "outputId": "c4615e6f-9ec7-40d1-84e0-b9fbee5f8730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+---+------+\n",
            "| fname| lname| Id|Sex|Salary|\n",
            "+------+------+---+---+------+\n",
            "| Smith|  Jone|123|  M| 20000|\n",
            "| Nance| watch|456|  F| 10000|\n",
            "|  Rani| Singh|234|  F| 30000|\n",
            "|  Raju|Thomas|897|  M| 15000|\n",
            "|Ranjan|Sharma|862|  M| 25000|\n",
            "+------+------+---+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField\n",
        "from pyspark.sql.types import IntegerType, StringType, ArrayType\n",
        "\n",
        "data2 = [(\"Aruna\", [\"Java\", \"Scala\", \"Python\"], \"India\", \"F\"),\n",
        "         (\"Smith\", [\"Pyspark\", \"C#\", \"Java\"], \"USA\", \"M\"),\n",
        "         (\"Jacob\", [\"Java\", \"C\", \"Javascript\"], \"USA\", \"M\"),\n",
        "         (\"chenchu\", [\"Scala\", \"C\", \"Python\"], \"China\", \"M\"),\n",
        "         (\"Veena\", [\"C++\", \"Java\", \"Python\"], \"India\", \"F\")\n",
        "         ]\n",
        "schema = StructType([\n",
        "    StructField(\"Name\", StringType(), True), \n",
        "    StructField(\"Languages\", StringType(), True), \n",
        "    StructField(\"Country\", StringType(), True), \n",
        "    StructField(\"Gender\", StringType(), True) \n",
        "])\n",
        "\n",
        "df = spark.createDataFrame(data=data2, schema=schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAGZUdxoyqtv",
        "outputId": "f981ca4d-9163-4e03-c48c-fe1bda226c9f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Languages: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            "\n",
            "+-------+---------------------+-------+------+\n",
            "|Name   |Languages            |Country|Gender|\n",
            "+-------+---------------------+-------+------+\n",
            "|Aruna  |[Java, Scala, Python]|India  |F     |\n",
            "|Smith  |[Pyspark, C#, Java]  |USA    |M     |\n",
            "|Jacob  |[Java, C, Javascript]|USA    |M     |\n",
            "|chenchu|[Scala, C, Python]   |China  |M     |\n",
            "|Veena  |[C++, Java, Python]  |India  |F     |\n",
            "+-------+---------------------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark Where Filter Function | Multiple Conditions**"
      ],
      "metadata": {
        "id": "AwQpx4hI3g7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataFrame filter() with column conditions "
      ],
      "metadata": {
        "id": "8cHj8deI3ufQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df.Country == \"India\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1e49FvD31VK",
        "outputId": "35d2dbb8-599c-4e0d-a70b-53a6b518b209"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------------+-------+------+\n",
            "|Name |Languages            |Country|Gender|\n",
            "+-----+---------------------+-------+------+\n",
            "|Aruna|[Java, Scala, Python]|India  |F     |\n",
            "|Veena|[C++, Java, Python]  |India  |F     |\n",
            "+-----+---------------------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df.Gender != \"M\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT2zJNWe4Ne6",
        "outputId": "a6bce0dd-e2b7-4a4d-a313-7e54450c2217"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------------+-------+------+\n",
            "|Name |Languages            |Country|Gender|\n",
            "+-----+---------------------+-------+------+\n",
            "|Aruna|[Java, Scala, Python]|India  |F     |\n",
            "|Veena|[C++, Java, Python]  |India  |F     |\n",
            "+-----+---------------------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark filter with multiple conditions**"
      ],
      "metadata": {
        "id": "MnGQKPjn5P04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter((df.Gender == \"M\") & (df.Country == \"USA\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enLqmcai4sDO",
        "outputId": "f474eac3-831f-468a-a2f7-d5702c5750ec"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------------+-------+------+\n",
            "|Name |Languages            |Country|Gender|\n",
            "+-----+---------------------+-------+------+\n",
            "|Smith|[Pyspark, C#, Java]  |USA    |M     |\n",
            "|Jacob|[Java, C, Javascript]|USA    |M     |\n",
            "+-----+---------------------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filter based on List values**"
      ],
      "metadata": {
        "id": "hPvnCOIS5VKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "li = [\"China\", \"India\"]\n",
        "df.filter(df.Country.isin(li)).show()\n",
        "df.filter(~df.Country.isin(li)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz5Msnr95adr",
        "outputId": "701fc4ee-d2c2-47ec-e19b-cceac80f4457"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+-------+------+\n",
            "|   Name|           Languages|Country|Gender|\n",
            "+-------+--------------------+-------+------+\n",
            "|  Aruna|[Java, Scala, Pyt...|  India|     F|\n",
            "|chenchu|  [Scala, C, Python]|  China|     M|\n",
            "|  Veena| [C++, Java, Python]|  India|     F|\n",
            "+-------+--------------------+-------+------+\n",
            "\n",
            "+-----+--------------------+-------+------+\n",
            "| Name|           Languages|Country|Gender|\n",
            "+-----+--------------------+-------+------+\n",
            "|Smith| [Pyspark, C#, Java]|    USA|     M|\n",
            "|Jacob|[Java, C, Javascr...|    USA|     M|\n",
            "+-----+--------------------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filter based on startsWith(), endsWith() & contains()**"
      ],
      "metadata": {
        "id": "3IJ3pS1r6JTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df.Country.startswith(\"I\")).show()\n",
        "df.filter(df.Country.endswith(\"a\")).show()\n",
        "df.filter(df.Gender.contains(\"M\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxs0eo3R6Utx",
        "outputId": "bc301318-4359-4ce6-feaf-011248a92100"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+-------+------+\n",
            "| Name|           Languages|Country|Gender|\n",
            "+-----+--------------------+-------+------+\n",
            "|Aruna|[Java, Scala, Pyt...|  India|     F|\n",
            "|Veena| [C++, Java, Python]|  India|     F|\n",
            "+-----+--------------------+-------+------+\n",
            "\n",
            "+-------+--------------------+-------+------+\n",
            "|   Name|           Languages|Country|Gender|\n",
            "+-------+--------------------+-------+------+\n",
            "|  Aruna|[Java, Scala, Pyt...|  India|     F|\n",
            "|chenchu|  [Scala, C, Python]|  China|     M|\n",
            "|  Veena| [C++, Java, Python]|  India|     F|\n",
            "+-------+--------------------+-------+------+\n",
            "\n",
            "+-------+--------------------+-------+------+\n",
            "|   Name|           Languages|Country|Gender|\n",
            "+-------+--------------------+-------+------+\n",
            "|  Smith| [Pyspark, C#, Java]|    USA|     M|\n",
            "|  Jacob|[Java, C, Javascr...|    USA|     M|\n",
            "|chenchu|  [Scala, C, Python]|  China|     M|\n",
            "+-------+--------------------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark Discting to Drop Duplicates**\n",
        "\n",
        "\n",
        "\n",
        "`distinct()` function is used to drop the duplicate rows from the data frame whereas `dropDuplicates()` is used to doprows based on selected columns."
      ],
      "metadata": {
        "id": "29SxGaxh9QJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "data3 = [(\"James\", \"Sales\", 3000 ),\n",
        "         (\"Rani\", \"Marketing\", 4000),\n",
        "         (\"Jacob\", \"Sales\", 3500),\n",
        "         (\"Mathew\", \"Finance\", 5000),\n",
        "         (\"Maria\", \"Sales\", 4500),\n",
        "         (\"Jane\", \"Marketing\", 4500),\n",
        "         (\"Kumar\", \"Finance\", 5500),\n",
        "         (\"Saif\", \"Sales\", 6000),\n",
        "         (\"Sonu\", \"Finance\", 6400),\n",
        "         (\"Reema\", \"Sales\", 7000)]\n",
        "\n",
        "columns = [\"Name\", \"Department\", \"Salary\"]\n",
        "df = spark.createDataFrame(data = data3, schema = columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27jFYYH193tE",
        "outputId": "1c876ad8-3fe7-4af2-d594-74ee776ce6f7"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Salary: long (nullable = true)\n",
            "\n",
            "+------+----------+------+\n",
            "|Name  |Department|Salary|\n",
            "+------+----------+------+\n",
            "|James |Sales     |3000  |\n",
            "|Rani  |Marketing |4000  |\n",
            "|Jacob |Sales     |3500  |\n",
            "|Mathew|Finance   |5000  |\n",
            "|Maria |Sales     |4500  |\n",
            "|Jane  |Marketing |4500  |\n",
            "|Kumar |Finance   |5500  |\n",
            "|Saif  |Sales     |6000  |\n",
            "|Sonu  |Finance   |6400  |\n",
            "|Reema |Sales     |7000  |\n",
            "+------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get Distinct rows"
      ],
      "metadata": {
        "id": "0-7_neHmAF7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distinctDF = df.distinct()\n",
        "distinctDF.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg8CN_vxAIPk",
        "outputId": "ce67e62f-6895-41d5-a6da-676bcdcc3304"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+------+\n",
            "|Name  |Department|Salary|\n",
            "+------+----------+------+\n",
            "|Mathew|Finance   |5000  |\n",
            "|Maria |Sales     |4500  |\n",
            "|Sonu  |Finance   |6400  |\n",
            "|Saif  |Sales     |6000  |\n",
            "|James |Sales     |3000  |\n",
            "|Reema |Sales     |7000  |\n",
            "|Rani  |Marketing |4000  |\n",
            "|Jacob |Sales     |3500  |\n",
            "|Kumar |Finance   |5500  |\n",
            "|Jane  |Marketing |4500  |\n",
            "+------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To eliminate duplicate entries from multiple columns"
      ],
      "metadata": {
        "id": "cH93GgzTArJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropDisDF = df.dropDuplicates([\"Department\", \"Salary\"])\n",
        "dropDisDF.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLH_I6nQAv7a",
        "outputId": "e2994fad-7c8f-4a22-bd34-bca94cbda348"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+------+\n",
            "|Name  |Department|Salary|\n",
            "+------+----------+------+\n",
            "|Sonu  |Finance   |6400  |\n",
            "|Saif  |Sales     |6000  |\n",
            "|Rani  |Marketing |4000  |\n",
            "|Jane  |Marketing |4500  |\n",
            "|Jacob |Sales     |3500  |\n",
            "|Mathew|Finance   |5000  |\n",
            "|Maria |Sales     |4500  |\n",
            "|James |Sales     |3000  |\n",
            "|Reema |Sales     |7000  |\n",
            "|Kumar |Finance   |5500  |\n",
            "+------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`orderBy()` & `sort()` to arrange the columns in ascending or descending order on single or multiple functions."
      ],
      "metadata": {
        "id": "74KCR67nBb2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort(\"Salary\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuG0FKfABrlL",
        "outputId": "b9a70e82-2c94-46a6-a507-11c222fb7409"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+------+\n",
            "|Name  |Department|Salary|\n",
            "+------+----------+------+\n",
            "|James |Sales     |3000  |\n",
            "|Jacob |Sales     |3500  |\n",
            "|Rani  |Marketing |4000  |\n",
            "|Maria |Sales     |4500  |\n",
            "|Jane  |Marketing |4500  |\n",
            "|Mathew|Finance   |5000  |\n",
            "|Kumar |Finance   |5500  |\n",
            "|Saif  |Sales     |6000  |\n",
            "|Sonu  |Finance   |6400  |\n",
            "|Reema |Sales     |7000  |\n",
            "+------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.orderBy(\"Name\", \"Department\", \"Salary\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I70Yw44MB5ul",
        "outputId": "9f718fe3-b3c7-4ebf-8f73-e7918e1f6fa3"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+------+\n",
            "|Name  |Department|Salary|\n",
            "+------+----------+------+\n",
            "|Jacob |Sales     |3500  |\n",
            "|James |Sales     |3000  |\n",
            "|Jane  |Marketing |4500  |\n",
            "|Kumar |Finance   |5500  |\n",
            "|Maria |Sales     |4500  |\n",
            "|Mathew|Finance   |5000  |\n",
            "|Rani  |Marketing |4000  |\n",
            "|Reema |Sales     |7000  |\n",
            "|Saif  |Sales     |6000  |\n",
            "|Sonu  |Finance   |6400  |\n",
            "+------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.orderBy(df.Department.asc(), df.Salary.desc(), df.Name.asc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mugd_UM8CLJj",
        "outputId": "024d34cc-35f8-430e-9a8b-ac6a8fcc60f2"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+------+\n",
            "|  Name|Department|Salary|\n",
            "+------+----------+------+\n",
            "|  Sonu|   Finance|  6400|\n",
            "| Kumar|   Finance|  5500|\n",
            "|Mathew|   Finance|  5000|\n",
            "|  Jane| Marketing|  4500|\n",
            "|  Rani| Marketing|  4000|\n",
            "| Reema|     Sales|  7000|\n",
            "|  Saif|     Sales|  6000|\n",
            "| Maria|     Sales|  4500|\n",
            "| Jacob|     Sales|  3500|\n",
            "| James|     Sales|  3000|\n",
            "+------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "groupBy() function:used to collect identical data into groups\n",
        "\n",
        "It contains:\n",
        "*  count()\n",
        "*  mean()\n",
        "*  max()\n",
        "*  avg()\n",
        "*  sum()\n",
        "*  agg()\n",
        "*  pivot()"
      ],
      "metadata": {
        "id": "FCP3KnAkCzjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "data4 = [(\"James\", \"Sales\", 3000, \"USA\" ),\n",
        "         (\"Rani\", \"Marketing\", 4000, \"Nepal\"),\n",
        "         (\"Jacob\", \"Sales\", 3500, \"USA\"),\n",
        "         (\"Mathew\", \"Finance\", 5000, \"USA\"),\n",
        "         (\"Maria\", \"Sales\", 4500, \"Bangladesh\"),\n",
        "         (\"Jane\", \"Marketing\", 4500, \"USA\"),\n",
        "         (\"Kumar\", \"Finance\", 5500, \"India\"),\n",
        "         (\"Saif\", \"Sales\", 6000, \"India\"),\n",
        "         (\"Sonu\", \"Finance\", 6400, \"India\"),\n",
        "         (\"Reema\", \"Sales\", 7000, \"Nepal\")]\n",
        "\n",
        "columns = [\"Name\", \"Department\", \"Salary\", \"Country\"]\n",
        "df = spark.createDataFrame(data = data4, schema = columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-thXy32DVXe",
        "outputId": "7d5ce07e-799c-4d5b-a810-cd3c2eac096b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Salary: long (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            "\n",
            "+------+----------+------+----------+\n",
            "|Name  |Department|Salary|Country   |\n",
            "+------+----------+------+----------+\n",
            "|James |Sales     |3000  |USA       |\n",
            "|Rani  |Marketing |4000  |Nepal     |\n",
            "|Jacob |Sales     |3500  |USA       |\n",
            "|Mathew|Finance   |5000  |USA       |\n",
            "|Maria |Sales     |4500  |Bangladesh|\n",
            "|Jane  |Marketing |4500  |USA       |\n",
            "|Kumar |Finance   |5500  |India     |\n",
            "|Saif  |Sales     |6000  |India     |\n",
            "|Sonu  |Finance   |6400  |India     |\n",
            "|Reema |Sales     |7000  |Nepal     |\n",
            "+------+----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Department\").sum(\"Salary\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f7ic1NZD0XD",
        "outputId": "c1c59dd3-a1d5-41de-bd37-2f8857cca352"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|sum(Salary)|\n",
            "+----------+-----------+\n",
            "|Sales     |24000      |\n",
            "|Finance   |16900      |\n",
            "|Marketing |8500       |\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Salary\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_g4Y4zmEB6X",
        "outputId": "82c68328-57dc-409c-b1c3-3aa13d523154"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|Salary|count|\n",
            "+------+-----+\n",
            "|  7000|    1|\n",
            "|  5500|    1|\n",
            "|  6400|    1|\n",
            "|  4500|    2|\n",
            "|  4000|    1|\n",
            "|  6000|    1|\n",
            "|  3500|    1|\n",
            "|  3000|    1|\n",
            "|  5000|    1|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Department\").min(\"Salary\").show(truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Brjm8AtENYL",
        "outputId": "92e4fb6d-ab06-4c4c-dfc7-37f740f5e625"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|min(Salary)|\n",
            "+----------+-----------+\n",
            "|Sales     |3000       |\n",
            "|Finance   |5000       |\n",
            "|Marketing |4000       |\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Department\").mean(\"Salary\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nFjcs8wFXuo",
        "outputId": "a8082ad9-5243-49db-e163-12e81be8b571"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+\n",
            "|Department|avg(Salary)      |\n",
            "+----------+-----------------+\n",
            "|Sales     |4800.0           |\n",
            "|Finance   |5633.333333333333|\n",
            "|Marketing |4250.0           |\n",
            "+----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**groupBy() & aggregate functions on multiple columns**"
      ],
      "metadata": {
        "id": "oFDQ8D-5FtkU"
      }
    }
  ]
}