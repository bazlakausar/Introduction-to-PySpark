{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3Uqgr0Rjj-a",
        "outputId": "2a896cce-95e2-4e08-a120-286eca066468"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPF0jIGRjlfk"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwAfP0PUjpQd"
      },
      "source": [
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bFrMSPLjtHo"
      },
      "source": [
        "!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELyEUvt8jv8W"
      },
      "source": [
        "!pip install -q findspark\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdYD_NFIjyZh"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOziQaJVj2Nx"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "twvLZgw-j5dQ",
        "outputId": "53a7e8ca-014d-4fd4-ecfd-c355a9a7908b"
      },
      "source": [
        "findspark.find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.2.0-bin-hadoop3.2'"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edii0qlDj8jE"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3Bj7muvle8Q"
      },
      "source": [
        "To create an RDD from a list, use `parallelize()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adDu9q2xlC8h"
      },
      "source": [
        "dataList = [(\"Java\", 20000),(\"Python\", 10000),(\"Scala\", 2000)]\n",
        "rdd=spark.sparkContext.parallelize(dataList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX8cfXMLmF8l",
        "outputId": "d8cddac3-ba4e-4cff-c750-2a71fd6306cc"
      },
      "source": [
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Java', 20000), ('Python', 10000), ('Scala', 2000)]"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbQWAiV5nrBa"
      },
      "source": [
        "To create an RDD from an external source such as a text file, use `textFile()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUYhM3wRn2ZS"
      },
      "source": [
        "rdd2=spark.sparkContext.textFile(\"/content/input.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd8thPhToBA6",
        "outputId": "dbfa9988-c959-4d38-8625-f8bc7e1834d5"
      },
      "source": [
        "rdd2.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In business and in life, the most critical choices we make relate to people. Yet being a good judge of people is difficult. How do we get better at sizing up first impressions, at avoiding hiring mistakes, at correctly picking (and not missing) rising stars?',\n",
              " '',\n",
              " 'The easy thing to do is focus on extrinsic markers — academic scores, net worth, social status, job titles. Social media has allowed us to add new layers of extrinsic scoring: How many friends do they have on Facebook? Who do we know in common through LinkedIn? How many Twitter followers do they have?',\n",
              " '',\n",
              " 'But such extrinsic credentials and markers only tell one part of a person’s story. They are necessary, but not sufficient. What they miss are the “softer” and more nuanced intrinsic that are far more defining of a person’s character. You can teach skills; character and attitude, not so much.',\n",
              " '',\n",
              " 'Judging on extrinsic and skill-based factors is a relatively objective and straightforward exercise. Gauging softer traits such as will or attitude is much, much harder, and takes one-on-one contact, attentive listening, and careful observation. That’s why it’s important to approach a job interview more as an attitudinal audition than a question-and-answer period around skills.',\n",
              " '',\n",
              " 'Over the years, I have been collecting and reflecting upon questions that have helped me improve my people judgment, especially around personality and attitude. Here are ten key questions to help you better understand the intrinsic “why” and “how” behind a person:',\n",
              " '',\n",
              " '1. What is the talk-to-listen ratio? You want people who are self-confident and not afraid to express their views, but if the talk-to-listen ratio is anything north of 60%, you want to ask why. Is it because this person is self-important and not interested in learning from others — or just because he is nervous and rambling?',\n",
              " '',\n",
              " '2. Is this an energy-giver or -taker? There is a certain breed of people who just carry with them and unfortunately spread a negative energy. You know who they are. Alternatively, there are those who consistently carry and share a positivity and optimism towards life. There is a Chinese proverb that says that the best way to get energy is to give it. Energy-givers are compassionate, generous and the type of people with whom you immediately want to spend time.',\n",
              " '',\n",
              " '3. Is this person likely to “act” or “react” to a task? Some people immediately go into defensive, critical mode when given a new task. Others jump right into action and problem-solving mode. For most jobs, it’s the second kind you want.',\n",
              " '',\n",
              " '4. Does this person feel authentic or obsequious? There is nothing flattering about false praise, or people trying too hard to impress. Really good people don’t feel the need to “suck up.” Those who can just be themselves are more pleasant to work with.',\n",
              " '',\n",
              " '5. What’s the spouse like? One of my business partners gave me a great tip for interviewing a super important hire — go out with their spouse, partner, or closest friend. We are known by the company we keep.',\n",
              " '',\n",
              " '6. How does this person treat someone she doesn’t know? At the other end of the spectrum, observe how a person treats someone she barely knows. This is what I call a “taxi driver or server test.” Does the person have the openness and yes, kindness, to have a real conversation with a waiter at a restaurant or the driver of a taxi? Does she ignore them or treat them rudely?',\n",
              " '',\n",
              " '7 Is there an element of struggle in the person’s history? History matters. In our research for the book, Heart, Smarts, Guts, and Luck (Harvard Business Review Press, 2012), my co-authors and I found that around two-thirds of people who were “Guts-dominant” — those who had the desire to initiate and the ability to persevere so crucial in entrepreneurial ventures — had some financial hardship or other challenges in their formative years. Early failures and hardships shape one’s character as much or more than early successes.',\n",
              " '',\n",
              " '8. What has this person been reading? Reading gives depth, helps one understand one’s history, frames ideas, sparks new thoughts and nuances to existing perspectives, and keeps you apprised of current events. It’s a generalization, but the more interesting people I have met tend to read a lot — it’s a mark of intellectual curiosity.',\n",
              " '',\n",
              " '9. Would you ever want to go on a long car ride with this person? This is a variant of the “airport test.” Years ago at my first job, I was told about the thought-experiment of asking if you were stuck at an airport with a candidate, how would you really feel? In a similar fashion, is this the type of person with whom you could imagine going on a cross-country drive?',\n",
              " '',\n",
              " '10. Do you believe that this person is self-aware? My colleagues and I believe the most important pre-requisite to great leadership is self-awareness. Does this person have an intellectual honesty about who he is and his strengths and weaknesses? Does she have a desire to learn and take appropriate actions based on that awareness? It is usually a more difficult question to answer than the rest — but look for humility, and congruence between what the person thinks, says, and does.',\n",
              " '',\n",
              " 'Ask these ten questions about someone, or even a subset of them, and you’ll be on a path to being a better judge of people. ']"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIJm4gbZqwmL"
      },
      "source": [
        "# **DataFrame**\n",
        "Simplest way to create a dataframe is by using Python `list`.\n",
        "\n",
        "\n",
        "1.   using `createDataFrame()` method.\n",
        "2.   from external data sources.\n",
        "        * Files from local system\n",
        "        * HDFS\n",
        "        * SQL table\n",
        "\n",
        "  To read a csv from a local system, use \n",
        "\n",
        "      `df = spark.read.csv(\"/path/file.csv\")`\n",
        "      \n",
        "      `df.printSchema()`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx3nO0RJrWWI"
      },
      "source": [
        "data = [('Mathew','Sebastian','M','50000'),('Smith','Jones','M','60000'),('Franky','','M','50000'),('Julie','steves','F','70000'),('Ancy','Mathew','F','60000')]\n",
        "columns = [\"FirstName\",\"LastName\",\"Gender\",\"Salary\"]\n",
        "df = spark.createDataFrame(data=data, schema = columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBUvu5bDtdlI"
      },
      "source": [
        "To get the schema of data frame, use `df.printSchema()`.\n",
        "(Since, data frames are structure format with has names and column)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cavghOUNtMAn",
        "outputId": "dd822ba3-f439-44a2-a797-ab4a69c80cf2"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- FirstName: string (nullable = true)\n",
            " |-- LastName: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSz7Tizut3XT"
      },
      "source": [
        "To see the elements of the created data frame, use `df.show()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmjwYC7RtRP9",
        "outputId": "45f40722-4e6e-402d-f73d-255ea6b78481"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|FirstName| LastName|Gender|Salary|\n",
            "+---------+---------+------+------+\n",
            "|   Mathew|Sebastian|     M| 50000|\n",
            "|    Smith|    Jones|     M| 60000|\n",
            "|   Franky|         |     M| 50000|\n",
            "|    Julie|   steves|     F| 70000|\n",
            "|     Ancy|   Mathew|     F| 60000|\n",
            "+---------+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NJ8vOkIx-oV"
      },
      "source": [
        "Spark `show()` method takes several arguments to fetch number of rows & get full column value:\n",
        "\n",
        "\n",
        "1.   `df.show(4)` //shows only top 4 rows\n",
        "2.   `df.show(truncate=False)` //shows all the rows with full column values\n",
        "3.   `df.show(4,truncate=False)` //shows only top 4 rows with full column values\n",
        "4.   `df.show(3,truncate=3,vertical=True)` //shows top 3 rows with full column   values in a vertical fashion.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeCu7V_VwgBH",
        "outputId": "ca4f7a99-aa94-4d2d-e62d-4f3b54a9091d"
      },
      "source": [
        "df.show(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|FirstName| LastName|Gender|Salary|\n",
            "+---------+---------+------+------+\n",
            "|   Mathew|Sebastian|     M| 50000|\n",
            "|    Smith|    Jones|     M| 60000|\n",
            "|   Franky|         |     M| 50000|\n",
            "|    Julie|   steves|     F| 70000|\n",
            "+---------+---------+------+------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKGG2ZsOxaSb",
        "outputId": "51244022-1882-4233-d25f-bb976bf4067f"
      },
      "source": [
        "df.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|FirstName|LastName |Gender|Salary|\n",
            "+---------+---------+------+------+\n",
            "|Mathew   |Sebastian|M     |50000 |\n",
            "|Smith    |Jones    |M     |60000 |\n",
            "|Franky   |         |M     |50000 |\n",
            "|Julie    |steves   |F     |70000 |\n",
            "|Ancy     |Mathew   |F     |60000 |\n",
            "+---------+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc1nbSMmxhru",
        "outputId": "7cda7db5-b390-4bdc-dd69-bb3d8c1ab1bf"
      },
      "source": [
        "df.show(4,truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|FirstName|LastName |Gender|Salary|\n",
            "+---------+---------+------+------+\n",
            "|Mathew   |Sebastian|M     |50000 |\n",
            "|Smith    |Jones    |M     |60000 |\n",
            "|Franky   |         |M     |50000 |\n",
            "|Julie    |steves   |F     |70000 |\n",
            "+---------+---------+------+------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4CHOhP5xmv0",
        "outputId": "3c7e40f5-6457-4662-8cb2-71001da0a066"
      },
      "source": [
        "df.show(3,truncate=3,vertical=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0--------\n",
            " FirstName | Mat \n",
            " LastName  | Seb \n",
            " Gender    | M   \n",
            " Salary    | 500 \n",
            "-RECORD 1--------\n",
            " FirstName | Smi \n",
            " LastName  | Jon \n",
            " Gender    | M   \n",
            " Salary    | 600 \n",
            "-RECORD 2--------\n",
            " FirstName | Fra \n",
            " LastName  |     \n",
            " Gender    | M   \n",
            " Salary    | 500 \n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ6E0KpX3w5G"
      },
      "source": [
        "# Using `withColumn()` fuction in  PySpark\n",
        "`withColumn()` function is a transformation function of data frame which is used to change the value of an existing column, covert the data type of an existing column, createa new column etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ei_Dbjo5ppN"
      },
      "source": [
        "\n",
        "\n",
        "1.   Changing the data type of an existing column: In order to change the data type of an existing column you need to use `cast()` function long with the `withColumn()` function.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6hFCZ7U4-tg",
        "outputId": "f0f73374-b652-44bc-8914-4a613c4ccd41"
      },
      "source": [
        "from pyspark.sql.functions import col, lit\n",
        "df.withColumn(\"Salary\",col(\"Salary\").cast(\"Integer\"))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[FirstName: string, LastName: string, Gender: string, Salary: int]"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieBzEGsE5iLq",
        "outputId": "110c8787-157f-4cb0-cec2-b06dec7c45fe"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|FirstName| LastName|Gender|Salary|\n",
            "+---------+---------+------+------+\n",
            "|   Mathew|Sebastian|     M| 50000|\n",
            "|    Smith|    Jones|     M| 60000|\n",
            "|   Franky|         |     M| 50000|\n",
            "|    Julie|   steves|     F| 70000|\n",
            "|     Ancy|   Mathew|     F| 60000|\n",
            "+---------+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvH7IvqD6MkZ"
      },
      "source": [
        "2. Updating the value of an existing column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhDdDjCD7oVH",
        "outputId": "7b4ad720-97f4-4923-f465-34aa228ce495"
      },
      "source": [
        "df.withColumn(\"Salary\",col(\"Salary\")*2).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+--------+\n",
            "|FirstName| LastName|Gender|  Salary|\n",
            "+---------+---------+------+--------+\n",
            "|   Mathew|Sebastian|     M|100000.0|\n",
            "|    Smith|    Jones|     M|120000.0|\n",
            "|   Franky|         |     M|100000.0|\n",
            "|    Julie|   steves|     F|140000.0|\n",
            "|     Ancy|   Mathew|     F|120000.0|\n",
            "+---------+---------+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhOO2BL376yn"
      },
      "source": [
        "3. Updating the column based on a condition:to update a column value based on a condition by we have to use `When`  and `Otherwise`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue5VUSbE8R-S",
        "outputId": "4098cd23-717a-42b8-882d-6401ab44a21d"
      },
      "source": [
        "from pyspark.sql.functions import when\n",
        "df1=df.withColumn(\"Gender\",when(df.Gender == \"M\", \"Male\")\\\n",
        "              .when(df.Gender == \"F\", \"Female\")\\\n",
        "              .otherwise(df.Gender))\n",
        "df1.show()\n",
        "\n",
        "              "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|FirstName| LastName|Gender|Salary|\n",
            "+---------+---------+------+------+\n",
            "|   Mathew|Sebastian|  Male| 50000|\n",
            "|    Smith|    Jones|  Male| 60000|\n",
            "|   Franky|         |  Male| 50000|\n",
            "|    Julie|   steves|Female| 70000|\n",
            "|     Ancy|   Mathew|Female| 60000|\n",
            "+---------+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2NX2d-MApXt"
      },
      "source": [
        "3. Adding a new column into the data frame: In order to create a new column, pass the column name you wanted to the first argument of `withColumn()` transformation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbX8eqOJAXbd",
        "outputId": "2b3259c0-3b17-4169-ef0b-62d787797696"
      },
      "source": [
        "df1.withColumn(\"Country\", lit(\"USA\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+-------+\n",
            "|FirstName| LastName|Gender|Salary|Country|\n",
            "+---------+---------+------+------+-------+\n",
            "|   Mathew|Sebastian|  Male| 50000|    USA|\n",
            "|    Smith|    Jones|  Male| 60000|    USA|\n",
            "|   Franky|         |  Male| 50000|    USA|\n",
            "|    Julie|   steves|Female| 70000|    USA|\n",
            "|     Ancy|   Mathew|Female| 60000|    USA|\n",
            "+---------+---------+------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxvNJQ3OBn4I",
        "outputId": "981fa11c-93f5-4468-d569-2f36415f2c53"
      },
      "source": [
        "df1.drop(\"Country\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|FirstName| LastName|Gender|Salary|\n",
            "+---------+---------+------+------+\n",
            "|   Mathew|Sebastian|  Male| 50000|\n",
            "|    Smith|    Jones|  Male| 60000|\n",
            "|   Franky|         |  Male| 50000|\n",
            "|    Julie|   steves|Female| 70000|\n",
            "|     Ancy|   Mathew|Female| 60000|\n",
            "+---------+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "digfd47uB3AA",
        "outputId": "588fd483-d00d-448f-cf87-355511d045df"
      },
      "source": [
        "df1.withColumn(\"Country\", lit(\"USA\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+-------+\n",
            "|FirstName| LastName|Gender|Salary|Country|\n",
            "+---------+---------+------+------+-------+\n",
            "|   Mathew|Sebastian|  Male| 50000|    USA|\n",
            "|    Smith|    Jones|  Male| 60000|    USA|\n",
            "|   Franky|         |  Male| 50000|    USA|\n",
            "|    Julie|   steves|Female| 70000|    USA|\n",
            "|     Ancy|   Mathew|Female| 60000|    USA|\n",
            "+---------+---------+------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5WB3dZBDFBT"
      },
      "source": [
        "# To filter rows based on a given condition\n",
        "PySpark `filter()` function is used to filter the rows from RDD/DataFrame based on the given condition or SQL expression, you can also use `where()` clause."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV8p3-eqDbPA",
        "outputId": "7e315538-2676-41de-c71e-6bbd684cb143"
      },
      "source": [
        "df1.filter(\"gender == 'Male'\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|FirstName| LastName|Gender|Salary|\n",
            "+---------+---------+------+------+\n",
            "|   Mathew|Sebastian|  Male| 50000|\n",
            "|    Smith|    Jones|  Male| 60000|\n",
            "|   Franky|         |  Male| 50000|\n",
            "+---------+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z682zK8bEhim",
        "outputId": "a06bc13a-43fd-4bd2-c216-5c5836fcd657"
      },
      "source": [
        "df1.filter(\"Gender != 'Male'\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------+------+\n",
            "|FirstName|LastName|Gender|Salary|\n",
            "+---------+--------+------+------+\n",
            "|    Julie|  steves|Female| 70000|\n",
            "|     Ancy|  Mathew|Female| 60000|\n",
            "+---------+--------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Pus7xF0Eq7t",
        "outputId": "6451a9a6-e155-4229-cbaa-f78bf4000208"
      },
      "source": [
        "df1.filter(\"Gender <> 'Male'\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------+------+\n",
            "|FirstName|LastName|Gender|Salary|\n",
            "+---------+--------+------+------+\n",
            "|    Julie|  steves|Female| 70000|\n",
            "|     Ancy|  Mathew|Female| 60000|\n",
            "+---------+--------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkCDY7dWE5OL"
      },
      "source": [
        "`Filter()` with multiple conditions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_Hog0ljFE7G",
        "outputId": "1a799f95-1422-4c41-b262-4f0ca3b8a187"
      },
      "source": [
        "df1.withColumn(\"Country\", lit(\"USA\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+-------+\n",
            "|FirstName| LastName|Gender|Salary|Country|\n",
            "+---------+---------+------+------+-------+\n",
            "|   Mathew|Sebastian|  Male| 50000|    USA|\n",
            "|    Smith|    Jones|  Male| 60000|    USA|\n",
            "|   Franky|         |  Male| 50000|    USA|\n",
            "|    Julie|   steves|Female| 70000|    USA|\n",
            "|     Ancy|   Mathew|Female| 60000|    USA|\n",
            "+---------+---------+------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkCGYCpPJbBk",
        "outputId": "24e8ab27-bc5a-4603-95a9-30dcac119c0f"
      },
      "source": [
        "df1.withColumn(\"Country\", lit(\"USA\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+-------+\n",
            "|FirstName| LastName|Gender|Salary|Country|\n",
            "+---------+---------+------+------+-------+\n",
            "|   Mathew|Sebastian|  Male| 50000|    USA|\n",
            "|    Smith|    Jones|  Male| 60000|    USA|\n",
            "|   Franky|         |  Male| 50000|    USA|\n",
            "|    Julie|   steves|Female| 70000|    USA|\n",
            "|     Ancy|   Mathew|Female| 60000|    USA|\n",
            "+---------+---------+------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abD7iHTmJjJI",
        "outputId": "7fa8c735-46c0-4f09-d0e7-0dd2d45b4a34"
      },
      "source": [
        "df1.filter(df1.Gender == \"Male\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|FirstName| LastName|Gender|Salary|\n",
            "+---------+---------+------+------+\n",
            "|   Mathew|Sebastian|  Male| 50000|\n",
            "|    Smith|    Jones|  Male| 60000|\n",
            "|   Franky|         |  Male| 50000|\n",
            "+---------+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoVgXFv7Kgyb",
        "outputId": "50f8b0cd-0bf8-43b9-a7c6-4258adff6fd1"
      },
      "source": [
        "df1.withColumn(\"Department\", lit(\"Finance\")) \\\n",
        ".show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+----------+\n",
            "|FirstName| LastName|Gender|Salary|Department|\n",
            "+---------+---------+------+------+----------+\n",
            "|   Mathew|Sebastian|  Male| 50000|   Finance|\n",
            "|    Smith|    Jones|  Male| 60000|   Finance|\n",
            "|   Franky|         |  Male| 50000|   Finance|\n",
            "|    Julie|   steves|Female| 70000|   Finance|\n",
            "|     Ancy|   Mathew|Female| 60000|   Finance|\n",
            "+---------+---------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RyoIHo_Lufz"
      },
      "source": [
        "df2=df1.withColumn(\"Department\", lit(\"Finance\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yq3IjQpL8sp",
        "outputId": "52fdfc13-6661-477c-a88c-8b539a2836f8"
      },
      "source": [
        "df2.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+----------+\n",
            "|FirstName| LastName|Gender|Salary|Department|\n",
            "+---------+---------+------+------+----------+\n",
            "|   Mathew|Sebastian|  Male| 50000|   Finance|\n",
            "|    Smith|    Jones|  Male| 60000|   Finance|\n",
            "|   Franky|         |  Male| 50000|   Finance|\n",
            "|    Julie|   steves|Female| 70000|   Finance|\n",
            "|     Ancy|   Mathew|Female| 60000|   Finance|\n",
            "+---------+---------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix1uaOCxNX7S"
      },
      "source": [
        "PySpark `orderBy()` and `sort()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRjXgjWTL_xm",
        "outputId": "e67c78c4-8c60-4fc1-8a45-460618a69cf2"
      },
      "source": [
        "\n",
        "df2.sort(\"Gender\",\"Department\").show(truncate=False)\n",
        "df2.sort(col(\"Gender\"),col(\"Department\")).show(truncate=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+----------+\n",
            "|FirstName|LastName |Gender|Salary|Department|\n",
            "+---------+---------+------+------+----------+\n",
            "|Julie    |steves   |Female|70000 |Finance   |\n",
            "|Ancy     |Mathew   |Female|60000 |Finance   |\n",
            "|Mathew   |Sebastian|Male  |50000 |Finance   |\n",
            "|Smith    |Jones    |Male  |60000 |Finance   |\n",
            "|Franky   |         |Male  |50000 |Finance   |\n",
            "+---------+---------+------+------+----------+\n",
            "\n",
            "+---------+---------+------+------+----------+\n",
            "|FirstName|LastName |Gender|Salary|Department|\n",
            "+---------+---------+------+------+----------+\n",
            "|Julie    |steves   |Female|70000 |Finance   |\n",
            "|Ancy     |Mathew   |Female|60000 |Finance   |\n",
            "|Mathew   |Sebastian|Male  |50000 |Finance   |\n",
            "|Smith    |Jones    |Male  |60000 |Finance   |\n",
            "|Franky   |         |Male  |50000 |Finance   |\n",
            "+---------+---------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOZJIuIUMpUr",
        "outputId": "e45cb735-0df6-46f9-9741-4714f9f7ea77"
      },
      "source": [
        "\n",
        "df2.sort(df2.Salary.asc(),df2.Department.asc()).show(truncate=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+----------+\n",
            "|FirstName|LastName |Gender|Salary|Department|\n",
            "+---------+---------+------+------+----------+\n",
            "|Mathew   |Sebastian|Male  |50000 |Finance   |\n",
            "|Franky   |         |Male  |50000 |Finance   |\n",
            "|Smith    |Jones    |Male  |60000 |Finance   |\n",
            "|Ancy     |Mathew   |Female|60000 |Finance   |\n",
            "|Julie    |steves   |Female|70000 |Finance   |\n",
            "+---------+---------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_fElS2YNmZ0",
        "outputId": "3484f4db-ba50-405f-983b-edd1876ec54b"
      },
      "source": [
        "df2.sort(df2.Salary.desc(),df2.Department.desc()).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+----------+\n",
            "|FirstName|LastName |Gender|Salary|Department|\n",
            "+---------+---------+------+------+----------+\n",
            "|Julie    |steves   |Female|70000 |Finance   |\n",
            "|Ancy     |Mathew   |Female|60000 |Finance   |\n",
            "|Smith    |Jones    |Male  |60000 |Finance   |\n",
            "|Mathew   |Sebastian|Male  |50000 |Finance   |\n",
            "|Franky   |         |Male  |50000 |Finance   |\n",
            "+---------+---------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ5DSlQnOJB0"
      },
      "source": [
        "# PySpark Explode arrays & map columns to rows\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwlTvJBbOtWU"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nCdvWikSMnP"
      },
      "source": [
        "Before we start, let’s create a DataFrame with array and map fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghpy31GJOvxP",
        "outputId": "1d3d0197-34e9-4cca-8d5d-d200fc5b68cf"
      },
      "source": [
        "arrayData = [\n",
        "             ('James',['Java','Python'],{'Hair':'Black','Eyes':'Brown'}),\n",
        "             ('Rani',['Scala','Java','Python'],{'Hair':'Brown','Eyes':'Black'}),\n",
        "             ('Mathew',['C','Java'],{'Hair':'Black','Eyes':'Blue'}),\n",
        "             ('Ancy',['Python','C','Java'],{'Hair':'Brown','Eyes':'Black'})\n",
        "\n",
        "]\n",
        "df = spark.createDataFrame(data=arrayData, schema = ['Name','LanguageKnown','Properties'])\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- LanguageKnown: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- Properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+------+--------------------+--------------------+\n",
            "|  Name|       LanguageKnown|          Properties|\n",
            "+------+--------------------+--------------------+\n",
            "| James|      [Java, Python]|{Hair -> Black, E...|\n",
            "|  Rani|[Scala, Java, Pyt...|{Hair -> Brown, E...|\n",
            "|Mathew|           [C, Java]|{Hair -> Black, E...|\n",
            "|  Ancy|   [Python, C, Java]|{Hair -> Brown, E...|\n",
            "+------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ag4Rgh9SU9F"
      },
      "source": [
        "PySpark function `explode(e: Column)` is used to explode or create array or map columns to rows. When an array is passed to this function, it creates a new default column `“col1”` and it contains all array elements. When a map is passed, it creates two new columns one for key and one for value and each element in map split into the rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r_pYiS1S0a2"
      },
      "source": [
        "**Explode - Array column**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC26HDIiSN8y",
        "outputId": "1545f3a1-690e-4d09-bdb2-3625c90b9989"
      },
      "source": [
        "from pyspark.sql.functions import explode\n",
        "df1 = df.select(df.Name, explode(df.LanguageKnown))\n",
        "df1.printSchema()\n",
        "df1.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- col: string (nullable = true)\n",
            "\n",
            "+------+------+\n",
            "|  Name|   col|\n",
            "+------+------+\n",
            "| James|  Java|\n",
            "| James|Python|\n",
            "|  Rani| Scala|\n",
            "|  Rani|  Java|\n",
            "|  Rani|Python|\n",
            "|Mathew|     C|\n",
            "|Mathew|  Java|\n",
            "|  Ancy|Python|\n",
            "|  Ancy|     C|\n",
            "|  Ancy|  Java|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_zvZuSaTd5o"
      },
      "source": [
        "**Explode - Map column**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjGwUE9JTksl"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy9Me08aVLPe",
        "outputId": "63ad3cc5-4e85-47f6-a0ab-73489018c792"
      },
      "source": [
        "arrayData = [\n",
        "             ('James',['Java','Python'],{'Hair':'Black','Eyes':'Brown'}),\n",
        "             ('Rani',['Scala','Java','Python'],{'Hair':'Brown','Eyes':'Black'}),\n",
        "             ('Mathew',['C','Java'],{'Hair':'Black','Eyes':'Blue'}),\n",
        "             ('Ancy',['Python','C','Java'],{'Hair':'Brown','Eyes':'Black'})\n",
        "\n",
        "]\n",
        "df = spark.createDataFrame(data=arrayData, schema = ['Name','LanguageKnown','Properties'])\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- LanguageKnown: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- Properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+------+--------------------+--------------------+\n",
            "|  Name|       LanguageKnown|          Properties|\n",
            "+------+--------------------+--------------------+\n",
            "| James|      [Java, Python]|{Hair -> Black, E...|\n",
            "|  Rani|[Scala, Java, Pyt...|{Hair -> Brown, E...|\n",
            "|Mathew|           [C, Java]|{Hair -> Black, E...|\n",
            "|  Ancy|   [Python, C, Java]|{Hair -> Brown, E...|\n",
            "+------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xvblfW-VTZR",
        "outputId": "9bea6273-d0e6-45c1-e988-2a4cbf12e6ed"
      },
      "source": [
        "from pyspark.sql.functions import explode\n",
        "df1 = df.select(df.Name, explode(df.Properties))\n",
        "df1.printSchema()\n",
        "df1.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- key: string (nullable = false)\n",
            " |-- value: string (nullable = true)\n",
            "\n",
            "+------+----+-----+\n",
            "|  Name| key|value|\n",
            "+------+----+-----+\n",
            "| James|Hair|Black|\n",
            "| James|Eyes|Brown|\n",
            "|  Rani|Hair|Brown|\n",
            "|  Rani|Eyes|Black|\n",
            "|Mathew|Hair|Black|\n",
            "|Mathew|Eyes| Blue|\n",
            "|  Ancy|Hair|Brown|\n",
            "|  Ancy|Eyes|Black|\n",
            "+------+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui9pzcOekmOX"
      },
      "source": [
        "PySpark Aggregate function\n",
        "PySpark SQL Aggregate functions are grouped as `“agg_funcs”` in Pyspark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX8vBkn4lKof"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86bV0zz3k0U7",
        "outputId": "4851b61d-0f4b-449c-d5d4-7d288d182712"
      },
      "source": [
        "\n",
        "simpleData = [(\"James\", \"Sales\", 3000),\n",
        "    (\"Michael\", \"Sales\", 4600),\n",
        "    (\"Robert\", \"Sales\", 4100),\n",
        "    (\"Maria\", \"Finance\", 3000),\n",
        "    (\"James\", \"Sales\", 3000),\n",
        "    (\"Scott\", \"Finance\", 3300),\n",
        "    (\"Jen\", \"Finance\", 3900),\n",
        "    (\"Jeff\", \"Marketing\", 3000),\n",
        "    (\"Kumar\", \"Marketing\", 2000),\n",
        "    (\"Saif\", \"Sales\", 4100)\n",
        "  ]\n",
        "schema = [\"employee_name\", \"department\", \"salary\"]\n",
        "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
        "df.printSchema()\n",
        "df.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|        James|     Sales|  3000|\n",
            "|      Michael|     Sales|  4600|\n",
            "|       Robert|     Sales|  4100|\n",
            "|        Maria|   Finance|  3000|\n",
            "|        James|     Sales|  3000|\n",
            "|        Scott|   Finance|  3300|\n",
            "|          Jen|   Finance|  3900|\n",
            "|         Jeff| Marketing|  3000|\n",
            "|        Kumar| Marketing|  2000|\n",
            "|         Saif|     Sales|  4100|\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}